This project is an implementation of a toxicity detection model using deep learning techniques. The model is designed to identify and classify toxic comments in text data. Toxicity in text can include hate speech, offensive language, and other harmful content.

The model is built using TensorFlow.
There are 5 phases in which the built was divided into-


1.Preprocessing:
tokenisation- each word maps to a number such that only deep learning model understands.

2.Building the model: Creating a sequential model
1st layer-embedding layer(knows in depth, analogy=personality of a word.)

3.Make predictions:Multiple comments as a batch passed together

4.Evaluation:binary classification metrics(accuracy, precision and recall scores)

5.Testing:
Custom input.

